---
title: "Probability of default (PD) model"
author: "Eligijus Bujokas"
date: "12/19/2020"
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(ggplot2)
library(zoo)
library(stringr)
library(gridExtra)
library(reshape)
library(pROC)
library(ROCR)
library(fastDummies)
library(tidytable)
Sys.setlocale("LC_ALL","C")
```

# Problem overview

The objective is to from the data that is in the *train.csv* file create a model that predicts the probability of default (PD) model. Then, the model is tested on the data that is in the file *test.csv*. 

The model will be a logistic regression model. 

# Reading data

```{r reading data}
train <- fread('data/train.csv')
test <- fread('data/test.csv')

featuresML <- fread('data/featuresMLPD.csv') %>% 
  na.omit(.) 
featuresML <- featuresML$V2

print(head(train))
print(head(test))

print(nrow(train))
print(nrow(test))
```

# Logistic regression model

## Creating the input matrix for the model 

```{r finalframe}
X = train[, ..featuresML]

# Creating the dummy variable matrix 
X <- get_dummies.(X, prefix_sep = ":") %>% 
  data.table(.)

# Creating a list of reference columns 
refCols <- c(
  "term:60 months", 
  "annual_incg:[0,30)",
  "dtig:30+",
  "emp_lengthg:< 1 year",
  "int_rateg:25+",
  "grade:G",
  "loan_amntg:22000+",
  "pub_recg:>0",
  "month_diffg:[0, 70)",
  "addr_stateg:OK:AL:AR:MS:NE",
  "purposeg:small_business"
  )

# Dropping the reference columns 
X <- X %>% 
  dplyr::select(., -all_of(refCols)) %>% 
  dplyr::select(., -all_of(featuresML))

# Final feature list 
featuresFinal = names(X)

# Adding the target variable
X$Y <- ifelse(train$Ypd=='good', 1, 0)
```

## Creating the model 

```{r logistic}
model <- glm(Y ~ ., data=X, family=binomial(link='logit'))

# Creating the coef frame 
coefFrame <- data.table('feature'=names(model$coefficients), 'coef'=model$coefficients)
coefFrame$feature <- gsub('`', '', coefFrame$feature)

# Saving the coef frame
write.csv(coefFrame, "modelPD.csv")

summary(model)
```

# Model performance on the test set 

```{r preparing input}
Xtest = test[, ..featuresML]

# Creating the testing dummies 
Xtest <- get_dummies.(Xtest, prefix_sep =":")

# Leaving only the final column list
Xtest <- Xtest %>% dplyr::select(., all_of(featuresFinal))

# Multiplying the test matrix with the coefficient vector
coefs <- model$coefficients[-1]
intercept <- model$coefficients[1]

product <- as.matrix(Xtest) %*% coefs
product <- product + intercept

# Getting the final probabilities 
yhat <- 1/(1 + exp(-product))
```

```{r inspecting the results}
test$yhat <- yhat

colsForLater <- c("Ypd", "yhat")

# Saving an object for the presentation
testPD <- test[, ..colsForLater]
write.csv(testPD, "PDresults.csv")

# Getting the ROC statistic 
ROC <- roc(test$Y, test$yhat)
roc_stat <- ROC$auc
print(paste("AUC score: ", roc_stat))
print(paste("Gini score: ", 2 * roc_stat - 1))
```

```{r clf visual}
par(mfrow=c(2, 2))
pred <- ROCR::prediction(test$yhat, test$Y)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, main='ROC plot')
abline(b=1, a=0, col='blue')

perf <- performance(pred, measure = "prec", x.measure = "cutoff")
plot(perf, main='Precision plot')

perf <- performance(pred, measure = "rec", x.measure = "cutoff")
plot(perf, main='Recall plot')
```

# Creating a scorecard 

The min score will be 200 and the max score will be 800. 

```{r coefs}
coefFrame <- data.table(feature=names(coefs), coef=coefs)
coefFrameRef <- data.table(feature=refCols, coef=0)
coefFrameIntercept <- data.table(feature='intercept', coef=intercept)

coefFrame <- rbind(coefFrame, coefFrameRef)
coefFrame <- rbind(coefFrame, coefFrameIntercept)

# Removing the ` symbol from the feature names 
coefFrame$feature <- gsub('`', '', coefFrame$feature)

# Getting the original name 
coefFrame[, c('origFeature') := tstrsplit(feature, ":")[[1]]]

# Defining the min and max score
min_score <- 200
max_score <- 800

# Getting the lowest possible scores from each feature
mincoef <- coefFrame[, .("coef_value"=min(coef)), by='origFeature']
maxcoef <- coefFrame[, .("coef_value"=max(coef)), by='origFeature']

# Summing all the values and adding the intercept to get the lowest and the biggest possible scores
sumMin <- sum(mincoef$coef_value)
sumMax <- sum(maxcoef$coef_value)
```

To convert the coefficient to a score, we need to follow the following formula:

$$score = coef\dfrac{(max\_score - min\_score)}{maxsum\_coef - minsum\_coef}$$

To adjust the coefficient for the intercept we will use the formula:

$$ score\_intercept = \dfrac{(intercept\_coef - min\_sum\_coef)}{(max\_sum\_coef - min\_sum\_coef)} (max\_score - min\_score) + min\_score $$

```{r scores}
coefFrame$score <- coefFrame$coef * (max_score - min_score) / (sumMax - sumMin)

scoreIntercept <- min_score + (max_score - min_score) * ((intercept - sumMin)/(sumMax - sumMin))

# Adding the value to the scorecard
coefFrame[feature=='intercept']$score <- scoreIntercept

# Rounding the scores
coefFrame$score_rounded <- sapply(coefFrame$score, round)

# Getting the differences 
coefFrame$diff <- coefFrame$score - coefFrame$score_rounded

# Getting the maximum score from the scorecard 
maxScoreCard <- coefFrame[, .('maxscore'=max(score_rounded)),  by='origFeature']
maxScoreCard <- sum(maxScoreCard$maxscore)
diff <- max_score - maxScoreCard

# Adding the difference to the biggest rounded group
coefFrame[diff==min(diff)]$score_rounded <- coefFrame[diff==min(diff)]$score_rounded + diff

# Getting the minum rounded error
minScoreCard <- coefFrame[, .('minscore'=min(score_rounded)),  by='origFeature']
minScoreCard <- sum(minScoreCard$minscore)
diff <- min_score - minScoreCard

# Adding the difference to the biggest rounded group
coefFrame[diff==max(diff)]$score_rounded <- coefFrame[diff==max(diff)]$score_rounded + diff

# Printing out the results
print(coefFrame)
```

The final scorecard: 

```{r final scorecard}
scorecard <- coefFrame[order(origFeature, -score_rounded)] %>% 
  .[, c('feature', 'score_rounded')]
print(scorecard)
```

```{r}
write.csv(test[,c('yhat')], 'test-all-PD.csv')
```
